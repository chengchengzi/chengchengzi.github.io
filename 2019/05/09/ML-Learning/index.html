<!DOCTYPE html>
<html lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no">
<meta name="author" content="Zhijuan">



<meta name="description" content="吴恩达，ML课程学习笔记">
<meta name="keywords" content="机器学习,ML">
<meta property="og:type" content="article">
<meta property="og:title" content="ML Learning">
<meta property="og:url" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/index.html">
<meta property="og:site_name" content="Zhijuan&#39;s Blog">
<meta property="og:description" content="吴恩达，ML课程学习笔记">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/2-1.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/3-3-1.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/特征归一化公式.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/多元线性回归梯度下降公式.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/3-3-1.JPG">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/3-3-2.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/logistic回归公式.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/logistic回归代价函数及其梯度下降.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/logistic用于多元分类.PNG">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/正则项线性回归.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/梯度下降求参.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/正规方程求参.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/正则项逻辑回归.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/梯度下降求参逻辑回归.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/简单的神经网络.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/反向传播1.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/反向传播2.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/反向传播3.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/双侧导数检验.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/神经网络训练过程.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/判断高偏差和高方差.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/正则化参数与高偏差高方差.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/学习曲线.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/benchmark.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/SVM优化函数.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/SVM求解参数.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/SVM无核.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/SVM其他核函数.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/SVM应对多分类.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/SVM逻辑回归方法选用.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/K均值聚类算法.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/K均值优化目标函数.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/K均值随机初始化.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/PCA步骤.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/PCA选取k.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/异常检测算法.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/异常检测如何选择epsilon.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/多元高斯分布模型.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/原始模型与多元高斯模型对比.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/推荐算法.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/协同过滤最小化目标函数.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/协议过滤算法描述.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/BGD.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/SGD.png">
<meta property="og:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/MBGD.png">
<meta property="og:updated_time" content="2019-05-30T03:49:14.517Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ML Learning">
<meta name="twitter:description" content="吴恩达，ML课程学习笔记">
<meta name="twitter:image" content="https://chengchengzi.github.io/2019/05/09/ML-Learning/2-1.png">

<link rel="apple-touch-icon" href="/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Zhijuan&#39;s Blog" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>ML Learning | Zhijuan&#39;s Blog</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: false
    }
</script>


    <script>
        yiliaConfig.jquery_ui = [true, "//cdn.bootcss.com/jqueryui/1.10.4/jquery-ui.min.js", "//cdn.bootcss.com/jqueryui/1.10.4/css/jquery-ui.min.css"];
    </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/orange.jpg" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Zhijuan</a></h1>
        </hgroup>

        
        <p class="header-subtitle">醉心于代码的世界</p>
        

        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">文章</a></li>
                        
                            <li><a href="/tags/">分类</a></li>
                        
                            <li><a href="/demos/">作品</a></li>
                        
                            <li><a href="/about/">ME</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=zq_goKelr727jr_-4K2how" title="Email"></a>
                            
                                <a class="fa GitHub" href="https://github.com/chengchengzi" title="GitHub"></a>
                            
                                <a class="fa QQ" href="tencent://message/?menu=yes&uin=1352715945&websitename=im.qq.com" title="QQ"></a>
                            
                                <a class="fa 微信" href="/15177327471" title="微信"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IO输入输出/">IO输入输出</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ML/">ML</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/STL/">STL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/原创/">原创</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/开篇/">开篇</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/模式设计/">模式设计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/记录/">记录</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/转载/">转载</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://github.com/chengchengzi">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://chengchengzi.github.io/">chengchengzi</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">不 忘 初 心, 方 得 始 终。</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">Zhijuan</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/orange.jpg" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">Zhijuan</a></h1>
            </hgroup>
            
            <p class="header-subtitle">醉心于代码的世界</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">文章</a></li>
                
                    <li><a href="/tags/">分类</a></li>
                
                    <li><a href="/demos/">作品</a></li>
                
                    <li><a href="/about/">ME</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=zq_goKelr727jr_-4K2how" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/chengchengzi" title="GitHub"></a>
                            
                                <a class="fa QQ" target="_blank" href="tencent://message/?menu=yes&uin=1352715945&websitename=im.qq.com" title="QQ"></a>
                            
                                <a class="fa 微信" target="_blank" href="/15177327471" title="微信"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我">
</nav>
      <div class="body-wrap"><article id="post-ML-Learning" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/05/09/ML-Learning/" class="article-date">
      <time datetime="2019-05-09T13:45:14.000Z" itemprop="datePublished">2019-05-09</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      ML Learning
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/AI/">AI</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ML/">ML</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>吴恩达，ML课程学习笔记</p>
<p><excerpt in index> </excerpt></p>
<ul>
<li><a id="more"></a>
<the rest of contents>

</the></li>
</ul>
<h1 id="一、-什么是机器学习？"><a href="#一、-什么是机器学习？" class="headerlink" title="一、 什么是机器学习？"></a>一、 什么是机器学习？</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><ul>
<li>Tom定义：一个程序被认为能从经验E中学习，解决任务T，达到性能度量值P，当且仅当，有了经验E后，经过P、评判，程序在处理T时的性能有所提升；</li>
<li>吴恩达认为：经验e 就是程序上万次的自我练习的经验而任务t就是下棋。性能度量值 p呢，就是它在与一些新的对手比赛时，赢得比赛的概率。</li>
</ul>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><ul>
<li>ML分为两大类：监督式学习和无监督式学习</li>
<li>监督式学习：数据集已经给出了人工标注，判断新的数据属于哪一类，比如：线性回归、逻辑回归、分类（已知样本类别);</li>
<li>无监督式学习：数据集未给出人工标注，也不知道有数据分为几类，无监督学习算法自动做分类，比如：聚类算法（未知样本类别);</li>
</ul>
<h1 id="二、单变量线性回归"><a href="#二、单变量线性回归" class="headerlink" title="二、单变量线性回归"></a>二、单变量线性回归</h1><h2 id="回归和分类都是监督学习问题"><a href="#回归和分类都是监督学习问题" class="headerlink" title="回归和分类都是监督学习问题"></a>回归和分类都是监督学习问题</h2><ul>
<li>回归：处理（预测）一组连续的值输出;</li>
<li>分类：处理（预测）少量离散值的输出;</li>
</ul>
<h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><ul>
<li>代价函数也被称为平方误差（代价）函数，在回归问题里比较常用；</li>
<li>为什么用平方误差？因为对于大多数问题，特别是归回问题，误差的平方和都是一个很合理的选择；举例：代价函数<br><img src="/2019/05/09/ML-Learning/2-1.png" alt="2-1"></li>
<li>代价函数中每一个 $θ_1$ 对于着不同的假设函数，当 $θ_1$ 最小时，对应拟合最优的直线（假设函数）这就是为什么要求去优化目标函数;</li>
</ul>
<h2 id="梯度下降算法最小化代价函数"><a href="#梯度下降算法最小化代价函数" class="headerlink" title="梯度下降算法最小化代价函数"></a>梯度下降算法最小化代价函数</h2><ul>
<li><img src="/2019/05/09/ML-Learning/3-3-1.png" alt="公式"></li>
<li>梯度下降法，越接近最低点，导数也越接近0，导数自动变得越来越小，梯度下降也会自动采用更小的幅度，没有必要再另外减小α;</li>
<li>实际上，线性回归的代价函数总是convex function(凸函数)，它只有一个全局最优解，梯度下降一定可以收敛到最小值;</li>
<li>Batch Gradient descent: 每一步梯度下降都使用了所有的训练样本;</li>
</ul>
<h1 id="三、多元线性回归（multivariate-linear-regression）"><a href="#三、多元线性回归（multivariate-linear-regression）" class="headerlink" title="三、多元线性回归（multivariate linear regression）"></a>三、多元线性回归（multivariate linear regression）</h1><h2 id="特征归一化"><a href="#特征归一化" class="headerlink" title="特征归一化"></a>特征归一化</h2><ul>
<li>多元线性回归指一个样本有多个特征；</li>
<li>特征缩放，即特征归一化, 公式如下：<br><img src="/2019/05/09/ML-Learning/特征归一化公式.png" alt="特征归一化公式"></li>
<li>进行特征归一化的原因：确保同一样本的不同特征取值在相近范围内，这个范围一般取 $-1 &lt; x_i &lt; 1$。归一化方法将特征统一量纲，能够提高模型的收敛速度和最终的模型精度，否则进行梯度下降的速度会很慢。</li>
</ul>
<h2 id="多元线性回归的梯度下降公式："><a href="#多元线性回归的梯度下降公式：" class="headerlink" title="多元线性回归的梯度下降公式："></a>多元线性回归的梯度下降公式：</h2><ul>
<li><img src="/2019/05/09/ML-Learning/多元线性回归梯度下降公式.png" alt="多元线性回归梯度下降公式"></li>
<li>梯度下降的目的是找道一个能最小化代价函数 $J(θ)$ 的 $θ$ 值;</li>
<li>关于学习率α：<ul>
<li>学习率α太小，$J(θ)$ 在每一步迭代会下降得很慢，也就是说收敛得很慢;</li>
<li>学习率α太大，$J(θ)$ 在每一步迭代不下降，或是可能不收敛;</li>
<li>选择一系列的α值, 然后选择一个使 $J(θ)$ 快速下降的α值;</li>
</ul>
</li>
</ul>
<h2 id="特征选择和多项式"><a href="#特征选择和多项式" class="headerlink" title="特征选择和多项式"></a>特征选择和多项式</h2><ul>
<li>可以自由选择不同的特征；</li>
<li>有时也会定义新的特征来得到更好的模型，新特征从旧特征得出，这时特征缩放就变得十分重要。</li>
</ul>
<h2 id="正规方程和梯度下降"><a href="#正规方程和梯度下降" class="headerlink" title="正规方程和梯度下降"></a>正规方程和梯度下降</h2><ul>
<li>正规方程求解<br><img src="/2019/05/09/ML-Learning/3-3-1.JPG" alt="正规方程求解公式"></li>
<li>两者之间的优缺点：<br><img src="/2019/05/09/ML-Learning/3-3-2.png" alt="正规方程和梯度下降两种算法的比较"></li>
<li>如果特征的维度n小于10000或者学习算法是线性回归的，选择正规方程求解；若果n很大或是学习算法很复杂用梯度下降算法。</li>
</ul>
<h1 id="四、Logistic回归"><a href="#四、Logistic回归" class="headerlink" title="四、Logistic回归"></a>四、Logistic回归</h1><h2 id="logistic回归定义"><a href="#logistic回归定义" class="headerlink" title="logistic回归定义"></a>logistic回归定义</h2><ul>
<li>logistic回归实际上是一种分类算法，是当今最流行，使用最广泛的学习算法之一；</li>
<li>特点：算法的输出或是预测值总是介于[0,1]之间；</li>
<li>logistic函数：<br><img src="/2019/05/09/ML-Learning/logistic回归公式.png" alt="lgistic函数"></li>
<li>决策边界（decision boundary）不是训练集的属性，而是假设函数本身及其参数的属性。一旦给定了参数θ，决策边界就确定了；</li>
<li>logistic回归可以用于寻找决策边界，用logistic回归函数作为假设函数，可以找到复杂的决策边界，从而获得较好的分类结果。</li>
</ul>
<h2 id="Logistic回归代价函数及其梯度下降"><a href="#Logistic回归代价函数及其梯度下降" class="headerlink" title="Logistic回归代价函数及其梯度下降"></a>Logistic回归代价函数及其梯度下降</h2><ul>
<li>Logistic回归函数及其梯度下降：<br><img src="/2019/05/09/ML-Learning/logistic回归代价函数及其梯度下降.png" alt></li>
<li>高级优化算法<ul>
<li>共轭梯度下降</li>
<li>BFGS</li>
<li>L-BFGS</li>
</ul>
</li>
</ul>
<h2 id="如何将Logistic回归应用于多类别分类："><a href="#如何将Logistic回归应用于多类别分类：" class="headerlink" title="如何将Logistic回归应用于多类别分类："></a>如何将Logistic回归应用于多类别分类：</h2><ul>
<li>构造伪数据集，训练得多分别属于每个类别假设函数的参数θ。<br><img src="/2019/05/09/ML-Learning/logistic用于多元分类.PNG" alt> </li>
</ul>
<h1 id="五、正则化"><a href="#五、正则化" class="headerlink" title="五、正则化"></a>五、正则化</h1><h2 id="算法拟合的情况："><a href="#算法拟合的情况：" class="headerlink" title="算法拟合的情况："></a>算法拟合的情况：</h2><ul>
<li>underfitting(欠拟合)：算法没有很好的拟合所有训练样本，具有高偏差（high bias）;</li>
<li>overfitting(过拟合):算法很好的拟合了所有的训练样本，但是拟合后的曲线波动过大，具有高方差（high variance）。过拟合在变量过多时出现，不能很好的泛化到新样本；</li>
</ul>
<h2 id="解决overfitting问题的方差"><a href="#解决overfitting问题的方差" class="headerlink" title="解决overfitting问题的方差"></a>解决overfitting问题的方差</h2><ul>
<li>法一：减少选取的特征变量数量<ul>
<li>人工检查特征变量清单，决定哪些特征是是比较重要的，保留或舍弃一些特征变量（弊端：会丢掉一些样本信息）</li>
</ul>
</li>
<li>法二：选择更合适的模型</li>
<li>法三：正则化：保留所有的特征变量，减少特征变量的两级或是参数 $θ_j $的大小。</li>
</ul>
<h2 id="正则化线性回归（减少参数-θ-j-）"><a href="#正则化线性回归（减少参数-θ-j-）" class="headerlink" title="正则化线性回归（减少参数$θ_j$ ）"></a>正则化线性回归（减少参数$θ_j$ ）</h2><ul>
<li>带有正则项的线性回归：<br><img src="/2019/05/09/ML-Learning/正则项线性回归.png" alt></li>
<li>式中第二项是正则项，对$ θ_1~θ_n$进行正则化，默认不正则化$θ_0$。<br>λ为正则参数（regularzation parameter）, 当 λ 太大，$θ_j$ 将趋于0，拟合的曲线将变为条平行于x轴，具有高偏差，也即出现欠拟合；<br>当λ太小，正则化不起作用，曲线依旧会过拟合。</li>
<li>求$θ_j$ 的方法有梯度下降法和正规方程<br><img src="/2019/05/09/ML-Learning/梯度下降求参.png" alt></li>
</ul>
<p><img src="/2019/05/09/ML-Learning/正规方程求参.png" alt></p>
<h2 id="正则化逻辑回归"><a href="#正则化逻辑回归" class="headerlink" title="正则化逻辑回归"></a>正则化逻辑回归</h2><ul>
<li>带有正则项的逻辑回归代价函数<br><img src="/2019/05/09/ML-Learning/正则项逻辑回归.png" alt></li>
<li>梯度下降<br><img src="/2019/05/09/ML-Learning/梯度下降求参逻辑回归.png" alt></li>
</ul>
<h1 id="六、神经网络"><a href="#六、神经网络" class="headerlink" title="六、神经网络"></a>六、神经网络</h1><ul>
<li>神经网络模仿了大脑中的神经元或神经网络，用来学习复杂的非线性假设模型；</li>
<li>weight = parameters</li>
<li>一个简单的神经网络模型如下（数学定义）：<br><img src="/2019/05/09/ML-Learning/简单的神经网络.png" alt></li>
<li>前向传播（forward peopagate）：一次计算激活项，从输入层到隐藏层再到输出层；</li>
<li>网络结构指不同的神经元的连接方式，可以计算出复杂的非线性假设函数；</li>
<li>利用神经网络可以解决多分类问题，即预测属于为n类；</li>
</ul>
<p>#七、神经网络的反向传播算法</p>
<ul>
<li>反向传播是计算代价函数关于所有参数的导数或偏导数的一种有效方法；</li>
<li>反向传播计算，用值计算神经网络代价函数的偏导数，只计算隐藏层的；</li>
<li>没有，因为不需要对输入层考虑误差；<br><img src="/2019/05/09/ML-Learning/反向传播1.png" alt><br><img src="/2019/05/09/ML-Learning/反向传播2.png" alt><br><img src="/2019/05/09/ML-Learning/反向传播3.png" alt></li>
<li>梯度检验<ul>
<li>梯度检验的目的：验证反向传播算法或是复杂算法的实现是否正确；</li>
<li>原因：神经网络的反向传播算法在实现中可能会存在一些bug，在这种情况下得到的神经网络的误差将会比无bug的情况高出一个量级；</li>
<li>采用双侧导数检验：<br><img src="/2019/05/09/ML-Learning/双侧导数检验.png" alt></li>
<li>验证计算出的导数和反向传播计算出的导数，其二者之间是否相近。如果二者相等或相近，则说明反向传播的实现是正确的；</li>
<li>验证完后，检查到实现是正确的，则在训练之前关掉检验；</li>
</ul>
</li>
<li>随机初始化<ul>
<li>需要随机初始化的原因：如果一开始令所有的权重初始值都为0，在逻辑回归里这是允许的，但是在神经网络里会出现问题，会出现高度冗余的现象，不会去学习任何特征；</li>
<li>如何解决？使用随机初始化为一个接近于0的范围,在-ε，ε]之间的数即可；</li>
</ul>
</li>
<li>神经网络训练过程<br>  分为6步：<pre><code>1. 构建一个神经网络并随机初始化权重（通常初始化为很小的值，接近于0）；
2. 前向传播算法得到h()的值，也就是输出y的向量；
3. 计算代价函数J；
4. 执行反向传播算法计算偏导数
5. 对所有的样本进行前向和反向传播算法后，得出激活项a^(l) 和激活项误差theta^(l)的值（通过这两个值可以计算出代价函数J的偏导数）后，进行梯度检查，检查实现的反向传播算法是否正确；正确则停用梯度检查；
6. 使用梯度下降或是其他高级优化算法以及反向传播，得出最优的J，训练完成。
</code></pre><img src="/2019/05/09/ML-Learning/神经网络训练过程.png" alt></li>
</ul>
<h1 id="八、应用机器学习的建议"><a href="#八、应用机器学习的建议" class="headerlink" title="八、应用机器学习的建议"></a>八、应用机器学习的建议</h1><h2 id="将数据分为训练集、交叉验证集或验证集、测试集"><a href="#将数据分为训练集、交叉验证集或验证集、测试集" class="headerlink" title="将数据分为训练集、交叉验证集或验证集、测试集"></a>将数据分为训练集、交叉验证集或验证集、测试集</h2><ul>
<li>对测试机的泛化误差进行多次度量，调整模型和超参数来得到拟合测试集的最佳模型。也就是说，这个算法模型更多是为测试集准备的，要求对新样本有很好的泛化能力。</li>
<li>如何做？做法是从数据中分出一个验证集，这样，模型可以适用多个不同的超参数，然后通过验证集，选择最好的模型及其相应的超参数。最后，使用测试进行测试，得到泛化误差的估值。</li>
<li><p>为了避免验证集浪费太多的训练数据，我们常用的技术就是交叉验证。即将训练集分成若干个互补的子集，然后每个模型都通过这些子集的不同组合来训练，之后用剩余的子集进行验证。当我们选择了一个模型和超参数之后，在对整个训练集训练一次，最后再用测试集测量泛化误差。</p>
</li>
<li><p>如何判断拟合曲线是高偏差（欠拟合）还是高方差（过拟合）<br><img src="/2019/05/09/ML-Learning/判断高偏差和高方差.png" alt></p>
</li>
<li>正则化参数lanbda与高偏差、高方差之间的联系<br><img src="/2019/05/09/ML-Learning/正则化参数与高偏差高方差.png" alt></li>
<li>学习曲线可以作为一种工具，用来检查算法是否一切正常或判断算法处于高偏差、高方差还是两者都有，从而改进算法的表现：<br><img src="/2019/05/09/ML-Learning/学习曲线.png" alt></li>
<li>设计复杂的机器学习算法过程中，如何在有限的时间内，让分类器具有高精度或是低错误率？推荐的方法：<ol>
<li>快速实现一个简单的学习算法</li>
<li>画学习曲线</li>
<li>进行误差分析</li>
<li>改进学习算法，不断地去尝试新方法，推荐在交叉验证集上误差分析。</li>
</ol>
</li>
</ul>
<h1 id="九、机器学习算法性能评估（benchmark）"><a href="#九、机器学习算法性能评估（benchmark）" class="headerlink" title="九、机器学习算法性能评估（benchmark）"></a>九、机器学习算法性能评估（benchmark）</h1><ul>
<li>准确率、精准率、召回率、F值<br><img src="/2019/05/09/ML-Learning/benchmark.png" alt></li>
</ul>
<h1 id="十、SVM（support-vector-machine）"><a href="#十、SVM（support-vector-machine）" class="headerlink" title="十、SVM（support vector machine）"></a>十、SVM（support vector machine）</h1><ul>
<li>SVM又称为大间距分类器，大间距指分类曲线与正负样本之间的距离都很远。由于在分类数据时会尽量用大的间距分类，这使得SVM具有很好的鲁棒性</li>
<li>SVM的总体优化目标<br><img src="/2019/05/09/ML-Learning/SVM优化函数.png" alt></li>
<li>样本的相似函数(similarity function) = 核函数;</li>
<li>参数C 和 $σ^2$， 参数C大，高方差；参数C小，高偏差;</li>
<li>使用SVM工具包,如liblinear,libsvm…去求解参数θ？<br><img src="/2019/05/09/ML-Learning/SVM求解参数.png" alt></li>
<li>线性核函数 = SVM 无核<br><img src="/2019/05/09/ML-Learning/SVM无核.png" alt><br><img src="/2019/05/09/ML-Learning/SVM其他核函数.png" alt></li>
<li>SVM 应对多分类问题<br><img src="/2019/05/09/ML-Learning/SVM应对多分类.png" alt></li>
<li>用逻辑回归还是SVM？对于不同情况下的数据样本，选用不同的方法：<br><img src="/2019/05/09/ML-Learning/SVM逻辑回归方法选用.png" alt></li>
</ul>
<h1 id="十一、无监督学习"><a href="#十一、无监督学习" class="headerlink" title="十一、无监督学习"></a>十一、无监督学习</h1><ul>
<li>无监督还是有监督，主要在于数据样本是否带标签；</li>
<li>无监督学习，将不带标签的数据分类，得出数据本身存在的结构；</li>
<li>K-means(K均值)是目前最为广泛的聚类算法，算法分为两步：<ol>
<li>Cluster assignment簇分配</li>
<li>Move centroid 移动聚类中心<br><img src="/2019/05/09/ML-Learning/K均值聚类算法.png" alt></li>
</ol>
</li>
<li>K均值优化目标函数<br><img src="/2019/05/09/ML-Learning/K均值优化目标函数.png" alt></li>
<li>如何初始化K均值聚类算法？</li>
<li>推荐使用随机初始化，即随机选取k个训练样本作为初始聚类中心，k &lt; m;</li>
<li>当k较小，可以进行多次随机初始化，选择聚类效果最好的一次；</li>
<li>当k较大，这个方法仍然有效；<br><img src="/2019/05/09/ML-Learning/K均值随机初始化.png" alt></li>
<li>如何选取聚类数量<ol>
<li>人工选取，根据经验估计，手动输入聚类数量；</li>
<li>Elbow method;</li>
<li>根据运行K均值算法的目的来选取，使用后续应用的评估标准，看哪个聚类数量能更好的应用与后续目的；</li>
</ol>
</li>
</ul>
<h1 id="十二、降维"><a href="#十二、降维" class="headerlink" title="十二、降维"></a>十二、降维</h1><ul>
<li>第二类无监督学习问题：降维</li>
<li>降维的目的是：<ol>
<li>数据压缩（data compression）：可以减少存储量以及加快算法的运行速度；</li>
<li>可视化：将数据画在2D或3D上，这样能更好的理解数据</li>
</ol>
</li>
<li>如何做降维：PCA主成分分析<ol>
<li>PCA试图找一个低维空间，然后对数据进行投影，计算样本点到投影点的最短距离，以便最小化正交投影的误差；</li>
<li>PCA不是线性回归，这是两个截然不同的算法。线性回归的目的是拟合出一条直线，最小化样本点到直线的垂直距离（y值的距离），输入x，输出预测的y值；而PCA计算的是样本点直线的最短距离。</li>
</ol>
</li>
<li>如何使用PCA降维，或者说如何找到被投影的低维空间？<br><img src="/2019/05/09/ML-Learning/PCA步骤.png" alt><ol>
<li>数据预处理，均值标准化/特征缩放</li>
<li>计算协方差矩阵sigma</li>
<li>对sigma进行SVD（奇异值分解）</li>
<li>取SVD后的U的前k个列向量，这k个列向量构成k维的低维空间</li>
<li>计算每个样本点投影到低维空间的z</li>
</ol>
</li>
<li>如何选取低维空间的维度k？<br><img src="/2019/05/09/ML-Learning/PCA选取k.png" alt></li>
<li>压缩重现，将x_approx = U * z, x_approx将会很接近于原来的x;</li>
<li>应用PCA的建议：<ol>
<li>如果k &lt;&lt; n, 这是不太合适的， k比n小一些不会影响算法的性能和分类的准确率；</li>
<li>当需要减少数据的存储或是确实证明了原始数据x无法用于计算时，才去考虑做PCA降维；</li>
</ol>
</li>
</ul>
<h1 id="十三、异常检测"><a href="#十三、异常检测" class="headerlink" title="十三、异常检测"></a>十三、异常检测</h1><ul>
<li>高斯分布 = 正态分布</li>
<li>异常检测算法：异常检测是指检查某个数据样本是否异常<br><img src="/2019/05/09/ML-Learning/异常检测算法.png" alt></li>
<li>如何选择epsilon?<br><img src="/2019/05/09/ML-Learning/异常检测如何选择epsilon.png" alt></li>
<li>用异常检测算法还是监督学习算法？当样本正常样本较多时，选用监督学习算法；当样本的异常样本较多时，且出现了异常的特征数据，用异常检测算法；</li>
<li>当画出的直方图不是高斯分布，需要调整数据，可以对原数据取对数或开根号，转为高斯分布</li>
<li>多元高斯分布，取不同的协方差矩阵和μ会得到不同的高斯分布模型</li>
<li>如何将多元高斯分布应用到异常检测算法中？<br><img src="/2019/05/09/ML-Learning/多元高斯分布模型.png" alt></li>
<li>原始模型与高斯分布模型对比：<br><img src="/2019/05/09/ML-Learning/原始模型与多元高斯模型对比.png" alt></li>
</ul>
<h1 id="十四、推荐系统"><a href="#十四、推荐系统" class="headerlink" title="十四、推荐系统"></a>十四、推荐系统</h1><ul>
<li>问题：推荐系统的问题是：如何根据用户行为去预测用户感兴趣的内容并给出推荐？</li>
<li>基于内容的推荐算法，其最优化目标函数和梯度下降：<br><img src="/2019/05/09/ML-Learning/推荐算法.png" alt></li>
<li>协同过滤（collaborative filtering）,自动进行特征学习<ol>
<li>最小化目标函数<br><img src="/2019/05/09/ML-Learning/协同过滤最小化目标函数.png" alt></li>
<li>协同过滤算法描述<br><img src="/2019/05/09/ML-Learning/协议过滤算法描述.png" alt></li>
</ol>
</li>
<li>可以用低秩矩阵分解进行预测，找到两个商品或是电影特征的最小距离，也就是它们的相似度，然后推荐给用户</li>
</ul>
<h1 id="十五、大规模机器学习"><a href="#十五、大规模机器学习" class="headerlink" title="十五、大规模机器学习"></a>十五、大规模机器学习</h1><ul>
<li>批量梯度下降（BGD：Batch Gradient descent）:直线找到全局最小值，在每一次迭代时使用所有样本进行梯度下降，更新参数。但是当样本量很大时，二米此迭代都需要对所有的样本进行计算，训练过程很慢。可并行计算。<br><img src="/2019/05/09/ML-Learning/BGD.png" alt></li>
<li>随机梯度下降（SGD：Stochastic Gradient descent）：曲折迂回的去找全局最小值，每次迭代使用一个样本对参数进行更新。这样做可以加快训练速度，但是准确率会下降，还可能收敛到局部最优，不易于并行计算。<br><img src="/2019/05/09/ML-Learning/SGD.png" alt></li>
<li>小批量梯度下降（MBGD：Mini-Batch Gradient descent）:每次迭代使用batch_size个样本对参数进行更新，是BGD和SGD的折中方法。收敛速度加快，准确率比SGD高，但是batch_size选择不当，可能会出现问题。易于并行计算。<br><img src="/2019/05/09/ML-Learning/MBGD.png" alt></li>
<li>在线学习机制：根据用户行为的变化数据，不断的进行学习，以更好的给用户推荐商品</li>
</ul>
<h1 id="十六、机器学习应用实例：照片OCR"><a href="#十六、机器学习应用实例：照片OCR" class="headerlink" title="十六、机器学习应用实例：照片OCR"></a>十六、机器学习应用实例：照片OCR</h1><ul>
<li>什么是OCR？Photo OCR 全称：Photo Optical character recognition 照片光学字符识别</li>
<li>pipline工作流：输入图片-》文字检测-》文字分割-》文字分类</li>
<li>文字检测：使用滑动窗口分类器，预先训练好分类器，然后在图像中截取矩形框进行分类，检测是否存在文字或行人</li>
<li>上限分析：给出工作流中每个板块最好情况下，计算分类性能，这样九可以知道应该将时间花在哪，提高哪一个模块的效果</li>
</ul>
<h1 id="十七、总结"><a href="#十七、总结" class="headerlink" title="十七、总结"></a>十七、总结</h1><ul>
<li>监督学习<ol>
<li>线性回归</li>
<li>逻辑虎归</li>
<li>神经网络</li>
<li>SVM</li>
</ol>
</li>
<li>无监督学习<ol>
<li>K-means</li>
<li>PCA</li>
<li>异常检测</li>
</ol>
</li>
<li>具体应用<ol>
<li>推荐系统</li>
<li>大规模机器学习</li>
</ol>
</li>
<li>在建立机器学习系统时的一些建议<ol>
<li>偏差/方差</li>
<li>正则化</li>
<li>评估算法性能</li>
<li>学习曲线</li>
<li>错误分析</li>
<li>工作流</li>
</ol>
</li>
</ul>

      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2019/05/09/ML-Learning/">ML Learning</a></p>
        <p><span>文章作者:</span><a href="/" title="回到主页">Zhijuan</a></p>
        <p><span>发布时间:</span>2019-05-09, 21:45:14</p>
        <p><span>最后更新:</span>2019-05-30, 11:49:14</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2019/05/09/ML-Learning/" title="ML Learning">https://chengchengzi.github.io/2019/05/09/ML-Learning/</a>
            <span class="copy-path" data-clipboard-text="原文: https://chengchengzi.github.io/2019/05/09/ML-Learning/　　作者: Zhijuan" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target="_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



    <nav id="article-nav">
        
            <div id="article-nav-newer" class="article-nav-title">
                <a href="/2019/05/12/Python学习笔记/">
                    Python学习笔记
                </a>
            </div>
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2019/04/08/C-之IO操作-博客迁移/">
                    C++之IO操作_博客迁移
                </a>
            </div>
        
    </nav>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">文章目录</strong>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#一、-什么是机器学习？"><span class="toc-number">1.</span> <span class="toc-text">一、 什么是机器学习？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#定义"><span class="toc-number">1.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#分类"><span class="toc-number">1.2.</span> <span class="toc-text">分类</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#二、单变量线性回归"><span class="toc-number">2.</span> <span class="toc-text">二、单变量线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#回归和分类都是监督学习问题"><span class="toc-number">2.1.</span> <span class="toc-text">回归和分类都是监督学习问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#代价函数"><span class="toc-number">2.2.</span> <span class="toc-text">代价函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#梯度下降算法最小化代价函数"><span class="toc-number">2.3.</span> <span class="toc-text">梯度下降算法最小化代价函数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#三、多元线性回归（multivariate-linear-regression）"><span class="toc-number">3.</span> <span class="toc-text">三、多元线性回归（multivariate linear regression）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#特征归一化"><span class="toc-number">3.1.</span> <span class="toc-text">特征归一化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多元线性回归的梯度下降公式："><span class="toc-number">3.2.</span> <span class="toc-text">多元线性回归的梯度下降公式：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#特征选择和多项式"><span class="toc-number">3.3.</span> <span class="toc-text">特征选择和多项式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#正规方程和梯度下降"><span class="toc-number">3.4.</span> <span class="toc-text">正规方程和梯度下降</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#四、Logistic回归"><span class="toc-number">4.</span> <span class="toc-text">四、Logistic回归</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#logistic回归定义"><span class="toc-number">4.1.</span> <span class="toc-text">logistic回归定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Logistic回归代价函数及其梯度下降"><span class="toc-number">4.2.</span> <span class="toc-text">Logistic回归代价函数及其梯度下降</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#如何将Logistic回归应用于多类别分类："><span class="toc-number">4.3.</span> <span class="toc-text">如何将Logistic回归应用于多类别分类：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#五、正则化"><span class="toc-number">5.</span> <span class="toc-text">五、正则化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#算法拟合的情况："><span class="toc-number">5.1.</span> <span class="toc-text">算法拟合的情况：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#解决overfitting问题的方差"><span class="toc-number">5.2.</span> <span class="toc-text">解决overfitting问题的方差</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#正则化线性回归（减少参数-θ-j-）"><span class="toc-number">5.3.</span> <span class="toc-text">正则化线性回归（减少参数$θ_j$ ）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#正则化逻辑回归"><span class="toc-number">5.4.</span> <span class="toc-text">正则化逻辑回归</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#六、神经网络"><span class="toc-number">6.</span> <span class="toc-text">六、神经网络</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#八、应用机器学习的建议"><span class="toc-number">7.</span> <span class="toc-text">八、应用机器学习的建议</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#将数据分为训练集、交叉验证集或验证集、测试集"><span class="toc-number">7.1.</span> <span class="toc-text">将数据分为训练集、交叉验证集或验证集、测试集</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#九、机器学习算法性能评估（benchmark）"><span class="toc-number">8.</span> <span class="toc-text">九、机器学习算法性能评估（benchmark）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#十、SVM（support-vector-machine）"><span class="toc-number">9.</span> <span class="toc-text">十、SVM（support vector machine）</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#十一、无监督学习"><span class="toc-number">10.</span> <span class="toc-text">十一、无监督学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#十二、降维"><span class="toc-number">11.</span> <span class="toc-text">十二、降维</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#十三、异常检测"><span class="toc-number">12.</span> <span class="toc-text">十三、异常检测</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#十四、推荐系统"><span class="toc-number">13.</span> <span class="toc-text">十四、推荐系统</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#十五、大规模机器学习"><span class="toc-number">14.</span> <span class="toc-text">十五、大规模机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#十六、机器学习应用实例：照片OCR"><span class="toc-number">15.</span> <span class="toc-text">十六、机器学习应用实例：照片OCR</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#十七、总结"><span class="toc-number">16.</span> <span class="toc-text">十七、总结</span></a></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-3 i,
        .toc-level-3 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="隐藏目录" title="点击按钮隐藏或者显示文章目录">

    <script>
        yiliaConfig.toc = ["隐藏目录", "显示目录", !!"true"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"ML Learning　| Zhijuan's Blog　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    




    <div class="scroll" id="post-nav-button">
        
            <a href="/2019/05/12/Python学习笔记/" title="上一篇: Python学习笔记">
                <i class="fa fa-angle-left"></i>
            </a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2019/04/08/C-之IO操作-博客迁移/" title="下一篇: C++之IO操作_博客迁移">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/09/08/《深入C-对象模型》笔记/">《深入C++对象模型》笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/07/设计模式学习笔记/">模式设计学习笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/01/《机器学习》周志华-笔记/">《机器学习》周志华-笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/12/Python学习笔记/">Python学习笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/09/ML-Learning/">ML Learning</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/08/C-之IO操作-博客迁移/">C++之IO操作_博客迁移</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/08/学习STL-博客迁移/">学习STL_博客迁移</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/08/开始Blog之旅-博客迁移/">开始Blog之旅_博客迁移</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/06/你好-Hexo/">你好,Hexo!</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/06/hello-world/">Hello World</a></li></ul>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2018-2019 Zhijuan
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style="display:none">
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style="display:none">
                        <span id="page-visit" title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 6;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

    <script>
        var originTitle = document.title;
        var titleTime;
        document.addEventListener("visibilitychange", function() {
            if (document.hidden) {
                document.title = "等你回来哦~ " + originTitle;
                clearTimeout(titleTime);
            }
            else {
                document.title = "欢迎回来哦~ " + originTitle;
                titleTime = setTimeout(function() {
                    document.title = originTitle;
                }, 2000);
            }
        })
    </script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body>
</html>